{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load('bool_q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <_PrefetchDataset element_spec={'answer': TensorSpec(shape=(), dtype=tf.bool, name=None), 'passage': TensorSpec(shape=(), dtype=tf.string, name=None), 'question': TensorSpec(shape=(), dtype=tf.string, name=None), 'title': TensorSpec(shape=(), dtype=tf.string, name=None)}>,\n",
       " 'validation': <_PrefetchDataset element_spec={'answer': TensorSpec(shape=(), dtype=tf.bool, name=None), 'passage': TensorSpec(shape=(), dtype=tf.string, name=None), 'question': TensorSpec(shape=(), dtype=tf.string, name=None), 'title': TensorSpec(shape=(), dtype=tf.string, name=None)}>}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = ds['train'], ds['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda sample : (sample['passage'], sample['title']))\n",
    "valid_ds = valid_ds.map(lambda sample : (sample['passage'], sample['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'There are four ways an individual can acquire Canadian citizenship: by birth on Canadian soil; by descent (being born to a Canadian parent); by grant (naturalization); and by adoption. Among them, only citizenship by birth is granted automatically with limited exceptions, while citizenship by descent or adoption is acquired automatically if the specified conditions have been met. Citizenship by grant, on the other hand, must be approved by the Minister of Immigration, Refugees and Citizenship.', shape=(), dtype=string) tf.Tensor(b'Canadian nationality law', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for text,label in train_ds.take(1):\n",
    "    print(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12697 12697 Star Trek: Discovery is an American television series created for CBS All Access by Bryan Fuller and Alex Kurtzman. It is the first series developed specifically for that service, and the first Star Trek series since Star Trek: Enterprise concluded in 2005. Set roughly a decade before the events of the original Star Trek series and separate from the timeline of the concurrently produced feature films, Discovery explores the Federation--Klingon war while following the crew of the USS Discovery. Gretchen J. Berg and Aaron Harberts serve as showrunners on the series, with producing support from Akiva Goldsman. Star Trek: Discovery\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "def general_function(dataset):\n",
    "    for text,label in dataset:\n",
    "        texts.append(text.numpy().decode('utf-8'))\n",
    "        labels.append(label.numpy().decode('utf-8'))\n",
    "\n",
    "general_function(train_ds)\n",
    "general_function(valid_ds)\n",
    "\n",
    "print(len(texts), len(labels), texts[1], labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'and': 3,\n",
       " 'in': 4,\n",
       " 'a': 5,\n",
       " 'to': 6,\n",
       " 'is': 7,\n",
       " 'as': 8,\n",
       " 'on': 9,\n",
       " 'by': 10,\n",
       " 'for': 11,\n",
       " 'with': 12,\n",
       " 'or': 13,\n",
       " 'was': 14,\n",
       " 'that': 15,\n",
       " 'it': 16,\n",
       " 'are': 17,\n",
       " 'from': 18,\n",
       " 'an': 19,\n",
       " 'be': 20,\n",
       " 'at': 21,\n",
       " 'states': 22,\n",
       " 'which': 23,\n",
       " 'united': 24,\n",
       " 'not': 25,\n",
       " 'has': 26,\n",
       " 'have': 27,\n",
       " 'also': 28,\n",
       " 'series': 29,\n",
       " 'one': 30,\n",
       " 'their': 31,\n",
       " 'its': 32,\n",
       " 'film': 33,\n",
       " 'they': 34,\n",
       " 'this': 35,\n",
       " 'first': 36,\n",
       " 'his': 37,\n",
       " 'season': 38,\n",
       " 'but': 39,\n",
       " 'two': 40,\n",
       " 'new': 41,\n",
       " 'other': 42,\n",
       " 'he': 43,\n",
       " 'may': 44,\n",
       " 'after': 45,\n",
       " 'world': 46,\n",
       " 'can': 47,\n",
       " 'all': 48,\n",
       " 'who': 49,\n",
       " 'her': 50,\n",
       " 'american': 51,\n",
       " 'when': 52,\n",
       " 'only': 53,\n",
       " 'been': 54,\n",
       " 'most': 55,\n",
       " 'were': 56,\n",
       " 'time': 57,\n",
       " 'used': 58,\n",
       " 's': 59,\n",
       " 'state': 60,\n",
       " 'such': 61,\n",
       " 'more': 62,\n",
       " 'into': 63,\n",
       " '1': 64,\n",
       " 'than': 65,\n",
       " 'she': 66,\n",
       " 'known': 67,\n",
       " 'u': 68,\n",
       " 'some': 69,\n",
       " 'while': 70,\n",
       " 'between': 71,\n",
       " 'if': 72,\n",
       " '2': 73,\n",
       " 'had': 74,\n",
       " 'no': 75,\n",
       " '2018': 76,\n",
       " '2017': 77,\n",
       " 'cup': 78,\n",
       " 'three': 79,\n",
       " 'game': 80,\n",
       " 'second': 81,\n",
       " 'there': 82,\n",
       " 'any': 83,\n",
       " 'over': 84,\n",
       " 'during': 85,\n",
       " 'will': 86,\n",
       " 'team': 87,\n",
       " 'up': 88,\n",
       " 'however': 89,\n",
       " 'law': 90,\n",
       " 'since': 91,\n",
       " 'national': 92,\n",
       " 'being': 93,\n",
       " 'both': 94,\n",
       " 'under': 95,\n",
       " 'where': 96,\n",
       " 'years': 97,\n",
       " 'same': 98,\n",
       " '3': 99,\n",
       " 'city': 100,\n",
       " 'north': 101,\n",
       " 'many': 102,\n",
       " 'would': 103,\n",
       " 'part': 104,\n",
       " 'games': 105,\n",
       " 'each': 106,\n",
       " 'based': 107,\n",
       " 'about': 108,\n",
       " 'including': 109,\n",
       " 'out': 110,\n",
       " 'called': 111,\n",
       " 'through': 112,\n",
       " 'name': 113,\n",
       " 'four': 114,\n",
       " 'before': 115,\n",
       " 'use': 116,\n",
       " 'number': 117,\n",
       " 'these': 118,\n",
       " 'year': 119,\n",
       " 'often': 120,\n",
       " 'south': 121,\n",
       " 'made': 122,\n",
       " \"''\": 123,\n",
       " 'television': 124,\n",
       " 'him': 125,\n",
       " 'system': 126,\n",
       " 'although': 127,\n",
       " '4': 128,\n",
       " 'released': 129,\n",
       " 'day': 130,\n",
       " '5': 131,\n",
       " '2016': 132,\n",
       " 'third': 133,\n",
       " 'later': 134,\n",
       " '10': 135,\n",
       " 'high': 136,\n",
       " 'war': 137,\n",
       " 'then': 138,\n",
       " 'well': 139,\n",
       " '2015': 140,\n",
       " 'i': 141,\n",
       " 'xbox': 142,\n",
       " 'league': 143,\n",
       " 'until': 144,\n",
       " 'york': 145,\n",
       " 'list': 146,\n",
       " 'best': 147,\n",
       " 'player': 148,\n",
       " 'area': 149,\n",
       " 'group': 150,\n",
       " 'because': 151,\n",
       " 'usually': 152,\n",
       " 'company': 153,\n",
       " 'family': 154,\n",
       " 'show': 155,\n",
       " 'set': 156,\n",
       " '000': 157,\n",
       " 'within': 158,\n",
       " 'them': 159,\n",
       " 'red': 160,\n",
       " 'won': 161,\n",
       " 'federal': 162,\n",
       " 'must': 163,\n",
       " 'president': 164,\n",
       " 'last': 165,\n",
       " 'five': 166,\n",
       " 'written': 167,\n",
       " 'water': 168,\n",
       " 'final': 169,\n",
       " 'america': 170,\n",
       " 'football': 171,\n",
       " 'age': 172,\n",
       " 'court': 173,\n",
       " 'home': 174,\n",
       " 'original': 175,\n",
       " 'act': 176,\n",
       " 'does': 177,\n",
       " 'fifa': 178,\n",
       " 'place': 179,\n",
       " 'british': 180,\n",
       " 'so': 181,\n",
       " 'laws': 182,\n",
       " 'episodes': 183,\n",
       " 'end': 184,\n",
       " 'million': 185,\n",
       " 'off': 186,\n",
       " 'common': 187,\n",
       " 'several': 188,\n",
       " 'canada': 189,\n",
       " 'public': 190,\n",
       " 'following': 191,\n",
       " '6': 192,\n",
       " '2014': 193,\n",
       " 'person': 194,\n",
       " '7': 195,\n",
       " 'major': 196,\n",
       " 'those': 197,\n",
       " 'long': 198,\n",
       " 'due': 199,\n",
       " 'produced': 200,\n",
       " 'kingdom': 201,\n",
       " 'june': 202,\n",
       " 'english': 203,\n",
       " 'do': 204,\n",
       " 'different': 205,\n",
       " 'air': 206,\n",
       " 'october': 207,\n",
       " 'life': 208,\n",
       " 'april': 209,\n",
       " 'm': 210,\n",
       " 'government': 211,\n",
       " 'played': 212,\n",
       " 'directed': 213,\n",
       " 'people': 214,\n",
       " '8': 215,\n",
       " 'back': 216,\n",
       " 'include': 217,\n",
       " 'september': 218,\n",
       " 'like': 219,\n",
       " 'island': 220,\n",
       " 'large': 221,\n",
       " 'found': 222,\n",
       " 'largest': 223,\n",
       " 'episode': 224,\n",
       " 'march': 225,\n",
       " 'play': 226,\n",
       " 'white': 227,\n",
       " 'right': 228,\n",
       " 'july': 229,\n",
       " 'story': 230,\n",
       " 'countries': 231,\n",
       " 'west': 232,\n",
       " 'e': 233,\n",
       " 'players': 234,\n",
       " 'song': 235,\n",
       " 'became': 236,\n",
       " 'located': 237,\n",
       " '2010': 238,\n",
       " 'term': 239,\n",
       " 'us': 240,\n",
       " 'against': 241,\n",
       " 'form': 242,\n",
       " 'ball': 243,\n",
       " 'school': 244,\n",
       " 'around': 245,\n",
       " 'house': 246,\n",
       " 'sometimes': 247,\n",
       " 'january': 248,\n",
       " '15': 249,\n",
       " 'without': 250,\n",
       " 'international': 251,\n",
       " 'six': 252,\n",
       " 'novel': 253,\n",
       " 'service': 254,\n",
       " 'legal': 255,\n",
       " 'announced': 256,\n",
       " 'created': 257,\n",
       " 'free': 258,\n",
       " 'john': 259,\n",
       " 'still': 260,\n",
       " 'character': 261,\n",
       " 'another': 262,\n",
       " '18': 263,\n",
       " 'premiered': 264,\n",
       " 'line': 265,\n",
       " 'even': 266,\n",
       " 'species': 267,\n",
       " 'own': 268,\n",
       " 'non': 269,\n",
       " 'considered': 270,\n",
       " 'order': 271,\n",
       " 'drama': 272,\n",
       " '2013': 273,\n",
       " 'book': 274,\n",
       " 'death': 275,\n",
       " 'though': 276,\n",
       " '12': 277,\n",
       " 'along': 278,\n",
       " 'members': 279,\n",
       " 'now': 280,\n",
       " 'england': 281,\n",
       " 'either': 282,\n",
       " 'king': 283,\n",
       " 'body': 284,\n",
       " 'single': 285,\n",
       " 'km': 286,\n",
       " 'times': 287,\n",
       " 'star': 288,\n",
       " 'force': 289,\n",
       " 'black': 290,\n",
       " 'c': 291,\n",
       " '20': 292,\n",
       " 'university': 293,\n",
       " 'light': 294,\n",
       " 'member': 295,\n",
       " 'required': 296,\n",
       " '2011': 297,\n",
       " '9': 298,\n",
       " 'office': 299,\n",
       " 'commonly': 300,\n",
       " 'began': 301,\n",
       " 'main': 302,\n",
       " 'generally': 303,\n",
       " 'east': 304,\n",
       " 'history': 305,\n",
       " 'days': 306,\n",
       " 'having': 307,\n",
       " 'seven': 308,\n",
       " 'production': 309,\n",
       " 'fourth': 310,\n",
       " 'texas': 311,\n",
       " 'november': 312,\n",
       " 'california': 313,\n",
       " 'country': 314,\n",
       " 'referred': 315,\n",
       " '0': 316,\n",
       " 'park': 317,\n",
       " 'point': 318,\n",
       " 'small': 319,\n",
       " 'similar': 320,\n",
       " 'central': 321,\n",
       " 'carry': 322,\n",
       " 'teams': 323,\n",
       " 'northern': 324,\n",
       " 'alcohol': 325,\n",
       " 'received': 326,\n",
       " 'power': 327,\n",
       " 'range': 328,\n",
       " 'born': 329,\n",
       " 'august': 330,\n",
       " 'named': 331,\n",
       " 'islands': 332,\n",
       " 'make': 333,\n",
       " 'once': 334,\n",
       " 'card': 335,\n",
       " 'constitution': 336,\n",
       " 'general': 337,\n",
       " '11': 338,\n",
       " 'typically': 339,\n",
       " 'example': 340,\n",
       " 'case': 341,\n",
       " 'man': 342,\n",
       " 'tv': 343,\n",
       " '30': 344,\n",
       " 'total': 345,\n",
       " 'stars': 346,\n",
       " '50': 347,\n",
       " 'result': 348,\n",
       " 'early': 349,\n",
       " 'did': 350,\n",
       " 'association': 351,\n",
       " 'sea': 352,\n",
       " 'great': 353,\n",
       " 'less': 354,\n",
       " '13': 355,\n",
       " 'much': 356,\n",
       " 'available': 357,\n",
       " 'december': 358,\n",
       " 'work': 359,\n",
       " 'title': 360,\n",
       " 'super': 361,\n",
       " 'open': 362,\n",
       " 'base': 363,\n",
       " 'held': 364,\n",
       " 'seasons': 365,\n",
       " '2012': 366,\n",
       " 'blue': 367,\n",
       " 'bank': 368,\n",
       " 'return': 369,\n",
       " 'just': 370,\n",
       " 'population': 371,\n",
       " 'award': 372,\n",
       " '24': 373,\n",
       " 'period': 374,\n",
       " '16': 375,\n",
       " 'february': 376,\n",
       " '21': 377,\n",
       " 'left': 378,\n",
       " 'per': 379,\n",
       " 'ireland': 380,\n",
       " 'video': 381,\n",
       " 'originally': 382,\n",
       " 'sequel': 383,\n",
       " 'current': 384,\n",
       " 'films': 385,\n",
       " 'western': 386,\n",
       " 'australia': 387,\n",
       " 'old': 388,\n",
       " 'special': 389,\n",
       " 'includes': 390,\n",
       " 'renewed': 391,\n",
       " 'century': 392,\n",
       " 'rights': 393,\n",
       " 'given': 394,\n",
       " 'level': 395,\n",
       " 'various': 396,\n",
       " 'down': 397,\n",
       " 'human': 398,\n",
       " 'way': 399,\n",
       " 'congress': 400,\n",
       " 'live': 401,\n",
       " 'very': 402,\n",
       " 'using': 403,\n",
       " 'together': 404,\n",
       " 'de': 405,\n",
       " 'role': 406,\n",
       " 'european': 407,\n",
       " 'become': 408,\n",
       " 'few': 409,\n",
       " 'former': 410,\n",
       " 'union': 411,\n",
       " 'half': 412,\n",
       " 'never': 413,\n",
       " 'published': 414,\n",
       " 'separate': 415,\n",
       " 'could': 416,\n",
       " 'take': 417,\n",
       " 'finals': 418,\n",
       " 'nba': 419,\n",
       " 'least': 420,\n",
       " 'd': 421,\n",
       " 'sold': 422,\n",
       " 'action': 423,\n",
       " 'blood': 424,\n",
       " '100': 425,\n",
       " 'uk': 426,\n",
       " '2009': 427,\n",
       " 'puerto': 428,\n",
       " 'run': 429,\n",
       " 'official': 430,\n",
       " 'river': 431,\n",
       " 'franchise': 432,\n",
       " 'version': 433,\n",
       " 'developed': 434,\n",
       " 'making': 435,\n",
       " '25': 436,\n",
       " 'among': 437,\n",
       " 'record': 438,\n",
       " 'citizenship': 439,\n",
       " 'square': 440,\n",
       " 'every': 441,\n",
       " 'thus': 442,\n",
       " 'upon': 443,\n",
       " 'station': 444,\n",
       " '2006': 445,\n",
       " 'field': 446,\n",
       " 'go': 447,\n",
       " 'republic': 448,\n",
       " 'language': 449,\n",
       " 'san': 450,\n",
       " 'standard': 451,\n",
       " 'local': 452,\n",
       " 'again': 453,\n",
       " 'certain': 454,\n",
       " 'months': 455,\n",
       " 'eight': 456,\n",
       " 'side': 457,\n",
       " 'county': 458,\n",
       " 'music': 459,\n",
       " 'mexico': 460,\n",
       " 'supreme': 461,\n",
       " '14': 462,\n",
       " 'win': 463,\n",
       " 'vehicle': 464,\n",
       " 'currently': 465,\n",
       " 'cannot': 466,\n",
       " 'top': 467,\n",
       " 'college': 468,\n",
       " 'french': 469,\n",
       " 'washington': 470,\n",
       " '19': 471,\n",
       " 'rico': 472,\n",
       " 'relationship': 473,\n",
       " 'areas': 474,\n",
       " 'bowl': 475,\n",
       " 'low': 476,\n",
       " 'green': 477,\n",
       " 'type': 478,\n",
       " 'land': 479,\n",
       " 'lead': 480,\n",
       " 'winning': 481,\n",
       " 'police': 482,\n",
       " 'aired': 483,\n",
       " 'full': 484,\n",
       " '2008': 485,\n",
       " 'network': 486,\n",
       " 'baseball': 487,\n",
       " 'g': 488,\n",
       " 'head': 489,\n",
       " '17': 490,\n",
       " '22': 491,\n",
       " 'cast': 492,\n",
       " 'oil': 493,\n",
       " 'speed': 494,\n",
       " 'see': 495,\n",
       " 'what': 496,\n",
       " 'young': 497,\n",
       " 'st': 498,\n",
       " 'fifth': 499,\n",
       " 'parts': 500,\n",
       " 'control': 501,\n",
       " 'gun': 502,\n",
       " 'capital': 503,\n",
       " 'europe': 504,\n",
       " 'hand': 505,\n",
       " 'mother': 506,\n",
       " 'characters': 507,\n",
       " 'release': 508,\n",
       " 'officially': 509,\n",
       " 'except': 510,\n",
       " 'love': 511,\n",
       " 'features': 512,\n",
       " 'center': 513,\n",
       " 'size': 514,\n",
       " 'outside': 515,\n",
       " 'ocean': 516,\n",
       " 'awards': 517,\n",
       " 'district': 518,\n",
       " 'military': 519,\n",
       " 'lost': 520,\n",
       " 'real': 521,\n",
       " 'michael': 522,\n",
       " 'florida': 523,\n",
       " 'miles': 524,\n",
       " 'dead': 525,\n",
       " 'ii': 526,\n",
       " 'natural': 527,\n",
       " 'tax': 528,\n",
       " 'get': 529,\n",
       " 'how': 530,\n",
       " '2007': 531,\n",
       " 'process': 532,\n",
       " 'across': 533,\n",
       " 'goal': 534,\n",
       " 'food': 535,\n",
       " 'france': 536,\n",
       " 'approximately': 537,\n",
       " 'next': 538,\n",
       " 'round': 539,\n",
       " 'canadian': 540,\n",
       " 'short': 541,\n",
       " 'events': 542,\n",
       " 'addition': 543,\n",
       " 'co': 544,\n",
       " 'throughout': 545,\n",
       " 'club': 546,\n",
       " 'southern': 547,\n",
       " 'previous': 548,\n",
       " 'london': 549,\n",
       " 'b': 550,\n",
       " 'highest': 551,\n",
       " 'issued': 552,\n",
       " 'you': 553,\n",
       " 'professional': 554,\n",
       " 'spanish': 555,\n",
       " 'rule': 556,\n",
       " 'studios': 557,\n",
       " 'region': 558,\n",
       " 'instead': 559,\n",
       " '23': 560,\n",
       " 'bill': 561,\n",
       " 'disney': 562,\n",
       " 'v': 563,\n",
       " 'division': 564,\n",
       " 'follows': 565,\n",
       " 'others': 566,\n",
       " 'program': 567,\n",
       " 'code': 568,\n",
       " 'turn': 569,\n",
       " 'citizens': 570,\n",
       " 'germany': 571,\n",
       " 'ground': 572,\n",
       " 'said': 573,\n",
       " 'related': 574,\n",
       " 'degree': 575,\n",
       " 'james': 576,\n",
       " 'popular': 577,\n",
       " 'sports': 578,\n",
       " 'included': 579,\n",
       " 'india': 580,\n",
       " 'eastern': 581,\n",
       " 'post': 582,\n",
       " 'introduced': 583,\n",
       " 'rules': 584,\n",
       " 'building': 585,\n",
       " 'move': 586,\n",
       " 'ten': 587,\n",
       " 'medical': 588,\n",
       " 'late': 589,\n",
       " 'development': 590,\n",
       " 'stadium': 591,\n",
       " 'sales': 592,\n",
       " 'individual': 593,\n",
       " 'championship': 594,\n",
       " 'street': 595,\n",
       " 'allowed': 596,\n",
       " 'party': 597,\n",
       " 'color': 598,\n",
       " 'engine': 599,\n",
       " 'cases': 600,\n",
       " '360': 601,\n",
       " 'near': 602,\n",
       " 'according': 603,\n",
       " 'prior': 604,\n",
       " 'led': 605,\n",
       " 'lower': 606,\n",
       " 'higher': 607,\n",
       " '2005': 608,\n",
       " 'below': 609,\n",
       " 'nations': 610,\n",
       " 'seen': 611,\n",
       " 'stores': 612,\n",
       " 'little': 613,\n",
       " 'carolina': 614,\n",
       " 'limited': 615,\n",
       " 'allow': 616,\n",
       " 'backward': 617,\n",
       " 'license': 618,\n",
       " 'executive': 619,\n",
       " 'present': 620,\n",
       " 'business': 621,\n",
       " 'refers': 622,\n",
       " 'lake': 623,\n",
       " 'space': 624,\n",
       " 'children': 625,\n",
       " 'father': 626,\n",
       " 'harry': 627,\n",
       " 'cell': 628,\n",
       " 'added': 629,\n",
       " 'multiple': 630,\n",
       " 'criminal': 631,\n",
       " 'coast': 632,\n",
       " 'section': 633,\n",
       " 'health': 634,\n",
       " 'queen': 635,\n",
       " 'modern': 636,\n",
       " 'should': 637,\n",
       " 'names': 638,\n",
       " '1998': 639,\n",
       " 'further': 640,\n",
       " 'ever': 641,\n",
       " 'musical': 642,\n",
       " 'virginia': 643,\n",
       " '2004': 644,\n",
       " 'playing': 645,\n",
       " 'additional': 646,\n",
       " 'basketball': 647,\n",
       " 'primary': 648,\n",
       " 'good': 649,\n",
       " 'mi': 650,\n",
       " 'services': 651,\n",
       " 'despite': 652,\n",
       " '2002': 653,\n",
       " 'female': 654,\n",
       " 'night': 655,\n",
       " 'value': 656,\n",
       " 'produce': 657,\n",
       " 'simply': 658,\n",
       " 'travel': 659,\n",
       " 'fictional': 660,\n",
       " 'bridge': 661,\n",
       " 'german': 662,\n",
       " 'tells': 663,\n",
       " 'uses': 664,\n",
       " 'tournament': 665,\n",
       " 'followed': 666,\n",
       " 'cause': 667,\n",
       " 'practice': 668,\n",
       " 'established': 669,\n",
       " 'los': 670,\n",
       " 'j': 671,\n",
       " 'took': 672,\n",
       " 'permit': 673,\n",
       " '26': 674,\n",
       " 'market': 675,\n",
       " 'directly': 676,\n",
       " 'sign': 677,\n",
       " 'support': 678,\n",
       " 'ice': 679,\n",
       " 'pacific': 680,\n",
       " 'department': 681,\n",
       " 'help': 682,\n",
       " 'birth': 683,\n",
       " 'able': 684,\n",
       " 'consists': 685,\n",
       " 'forces': 686,\n",
       " 't': 687,\n",
       " 'unlike': 688,\n",
       " 'position': 689,\n",
       " 'town': 690,\n",
       " 'road': 691,\n",
       " 'mark': 692,\n",
       " 'marvel': 693,\n",
       " 'george': 694,\n",
       " 'drive': 695,\n",
       " 'gold': 696,\n",
       " 'drinking': 697,\n",
       " 'whether': 698,\n",
       " 'worldwide': 699,\n",
       " 'owned': 700,\n",
       " 'band': 701,\n",
       " 'atlantic': 702,\n",
       " 'airport': 703,\n",
       " 'types': 704,\n",
       " 'army': 705,\n",
       " 'provided': 706,\n",
       " 'appearance': 707,\n",
       " 'built': 708,\n",
       " 'served': 709,\n",
       " 'length': 710,\n",
       " 'longer': 711,\n",
       " 'energy': 712,\n",
       " 'above': 713,\n",
       " 'private': 714,\n",
       " 'summer': 715,\n",
       " '1994': 716,\n",
       " 'pressure': 717,\n",
       " 'dark': 718,\n",
       " 'depending': 719,\n",
       " 'larger': 720,\n",
       " 'nfl': 721,\n",
       " 'close': 722,\n",
       " 'income': 723,\n",
       " 'car': 724,\n",
       " 'direct': 725,\n",
       " 'away': 726,\n",
       " 'amendment': 727,\n",
       " 'eventually': 728,\n",
       " 'date': 729,\n",
       " 'designed': 730,\n",
       " 'feet': 731,\n",
       " 'compatible': 732,\n",
       " 'allows': 733,\n",
       " 'civil': 734,\n",
       " 'church': 735,\n",
       " 'royal': 736,\n",
       " 'performance': 737,\n",
       " 'crime': 738,\n",
       " 'whose': 739,\n",
       " 'specific': 740,\n",
       " 'child': 741,\n",
       " 'security': 742,\n",
       " 'takes': 743,\n",
       " 'points': 744,\n",
       " '28': 745,\n",
       " '27': 746,\n",
       " 'angeles': 747,\n",
       " 'concealed': 748,\n",
       " 'brown': 749,\n",
       " 'columbia': 750,\n",
       " 'possible': 751,\n",
       " 'especially': 752,\n",
       " 'change': 753,\n",
       " 'heart': 754,\n",
       " 'golden': 755,\n",
       " 'nine': 756,\n",
       " 'cards': 757,\n",
       " 'your': 758,\n",
       " 'caribbean': 759,\n",
       " 'social': 760,\n",
       " 'h': 761,\n",
       " 'rather': 762,\n",
       " 'middle': 763,\n",
       " 'surface': 764,\n",
       " 'article': 765,\n",
       " 'residents': 766,\n",
       " 'motor': 767,\n",
       " 'double': 768,\n",
       " 'zealand': 769,\n",
       " 'structure': 770,\n",
       " 'revealed': 771,\n",
       " 'stated': 772,\n",
       " '1990': 773,\n",
       " 'channel': 774,\n",
       " 'microsoft': 775,\n",
       " 'meaning': 776,\n",
       " 'trophy': 777,\n",
       " 'shot': 778,\n",
       " 'rate': 779,\n",
       " 'languages': 780,\n",
       " 'sixth': 781,\n",
       " 'therefore': 782,\n",
       " 'fox': 783,\n",
       " 'rock': 784,\n",
       " 'previously': 785,\n",
       " 'playstation': 786,\n",
       " 'receive': 787,\n",
       " 'regular': 788,\n",
       " 'itself': 789,\n",
       " 'call': 790,\n",
       " 'contains': 791,\n",
       " 'described': 792,\n",
       " 'beginning': 793,\n",
       " 'loss': 794,\n",
       " 'africa': 795,\n",
       " 'mid': 796,\n",
       " 'mass': 797,\n",
       " 'hours': 798,\n",
       " 'director': 799,\n",
       " 'occur': 800,\n",
       " 'taken': 801,\n",
       " 'board': 802,\n",
       " '500': 803,\n",
       " 'david': 804,\n",
       " 'appeared': 805,\n",
       " 'firearms': 806,\n",
       " 'reached': 807,\n",
       " 'systems': 808,\n",
       " 'majority': 809,\n",
       " 'via': 810,\n",
       " 'r': 811,\n",
       " 'provide': 812,\n",
       " 'nation': 813,\n",
       " 'chicago': 814,\n",
       " 'mountain': 815,\n",
       " 'seventh': 816,\n",
       " 'trade': 817,\n",
       " 'stop': 818,\n",
       " 'chain': 819,\n",
       " 'visa': 820,\n",
       " 'died': 821,\n",
       " 'tower': 822,\n",
       " '31': 823,\n",
       " 'terms': 824,\n",
       " 'wars': 825,\n",
       " 'cells': 826,\n",
       " 'l': 827,\n",
       " 'stage': 828,\n",
       " 'comedy': 829,\n",
       " 'screenplay': 830,\n",
       " 'address': 831,\n",
       " 'far': 832,\n",
       " 'competition': 833,\n",
       " 'came': 834,\n",
       " 'respectively': 835,\n",
       " 'working': 836,\n",
       " 'prohibited': 837,\n",
       " 'male': 838,\n",
       " 'yellow': 839,\n",
       " 'identity': 840,\n",
       " 'territories': 841,\n",
       " 'movie': 842,\n",
       " 'means': 843,\n",
       " 'border': 844,\n",
       " 'find': 845,\n",
       " 'japan': 846,\n",
       " 'model': 847,\n",
       " 'running': 848,\n",
       " '2000': 849,\n",
       " 'china': 850,\n",
       " 'senate': 851,\n",
       " 'always': 852,\n",
       " 'native': 853,\n",
       " '29': 854,\n",
       " 'eye': 855,\n",
       " 'cross': 856,\n",
       " 'property': 857,\n",
       " 'vote': 858,\n",
       " 'qualify': 859,\n",
       " 'front': 860,\n",
       " 'married': 861,\n",
       " 'pass': 862,\n",
       " 'important': 863,\n",
       " 'humans': 864,\n",
       " 'normal': 865,\n",
       " 'physical': 866,\n",
       " 'greater': 867,\n",
       " 'associated': 868,\n",
       " 'twice': 869,\n",
       " 'product': 870,\n",
       " 'robert': 871,\n",
       " 'smaller': 872,\n",
       " 'actor': 873,\n",
       " 'jersey': 874,\n",
       " 'salt': 875,\n",
       " 'status': 876,\n",
       " 'independent': 877,\n",
       " 'replaced': 878,\n",
       " 'qualified': 879,\n",
       " 'we': 880,\n",
       " 'shall': 881,\n",
       " '2003': 882,\n",
       " 'defined': 883,\n",
       " 'fuel': 884,\n",
       " 'territory': 885,\n",
       " 'abc': 886,\n",
       " 'policy': 887,\n",
       " 'brother': 888,\n",
       " 'products': 889,\n",
       " 'pennsylvania': 890,\n",
       " 'access': 891,\n",
       " 'uefa': 892,\n",
       " 'adult': 893,\n",
       " 'leave': 894,\n",
       " 'indian': 895,\n",
       " \"world's\": 896,\n",
       " 'almost': 897,\n",
       " 'n': 898,\n",
       " 'x': 899,\n",
       " 'living': 900,\n",
       " 'recorded': 901,\n",
       " 'subject': 902,\n",
       " 'founded': 903,\n",
       " 'whole': 904,\n",
       " 'conference': 905,\n",
       " '00': 906,\n",
       " 'pictures': 907,\n",
       " 'dog': 908,\n",
       " 'makes': 909,\n",
       " 'gas': 910,\n",
       " 'primarily': 911,\n",
       " 'financial': 912,\n",
       " 'billion': 913,\n",
       " 'match': 914,\n",
       " 'opened': 915,\n",
       " 'true': 916,\n",
       " 'traffic': 917,\n",
       " 'commercial': 918,\n",
       " 'bar': 919,\n",
       " 'contain': 920,\n",
       " 'confirmed': 921,\n",
       " 'battle': 922,\n",
       " 'hit': 923,\n",
       " 'wild': 924,\n",
       " 'feature': 925,\n",
       " 'foreign': 926,\n",
       " 'p': 927,\n",
       " 'hospital': 928,\n",
       " 'effect': 929,\n",
       " 'himself': 930,\n",
       " 'amount': 931,\n",
       " 'pay': 932,\n",
       " 'becomes': 933,\n",
       " 'require': 934,\n",
       " 'fire': 935,\n",
       " 'motion': 936,\n",
       " 'universal': 937,\n",
       " 'peter': 938,\n",
       " 'adopted': 939,\n",
       " 'winners': 940,\n",
       " 'citizen': 941,\n",
       " 'word': 942,\n",
       " 'course': 943,\n",
       " 'finale': 944,\n",
       " 'zone': 945,\n",
       " 'failed': 946,\n",
       " 'box': 947,\n",
       " 'nearly': 948,\n",
       " 'passport': 949,\n",
       " 'ft': 950,\n",
       " 'money': 951,\n",
       " 'men': 952,\n",
       " 'unless': 953,\n",
       " 'greek': 954,\n",
       " 'superfecundation': 955,\n",
       " 'event': 956,\n",
       " 'semi': 957,\n",
       " 'me': 958,\n",
       " 'requires': 959,\n",
       " 'vehicles': 960,\n",
       " 'universe': 961,\n",
       " 'animals': 962,\n",
       " 'firearm': 963,\n",
       " 'provides': 964,\n",
       " 'behind': 965,\n",
       " 'comes': 966,\n",
       " 'hold': 967,\n",
       " 'going': 968,\n",
       " 'ended': 969,\n",
       " 'come': 970,\n",
       " 'numbers': 971,\n",
       " 'jack': 972,\n",
       " 'academy': 973,\n",
       " 'formed': 974,\n",
       " 'son': 975,\n",
       " 'reach': 976,\n",
       " 'design': 977,\n",
       " 'media': 978,\n",
       " 'cost': 979,\n",
       " 'forms': 980,\n",
       " 'temperature': 981,\n",
       " 'shooting': 982,\n",
       " 'illegal': 983,\n",
       " 'penalty': 984,\n",
       " 'bay': 985,\n",
       " 'operations': 986,\n",
       " 'variety': 987,\n",
       " 'starring': 988,\n",
       " 'draft': 989,\n",
       " 'acid': 990,\n",
       " 'consecutive': 991,\n",
       " 'leading': 992,\n",
       " 'studio': 993,\n",
       " 'william': 994,\n",
       " 'too': 995,\n",
       " '1999': 996,\n",
       " 'goes': 997,\n",
       " 'premiere': 998,\n",
       " 'saint': 999,\n",
       " 'particular': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the complete dataset (training and testing) for text generation\n",
    "data_to_tokenize = texts + labels\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data_to_tokenize)\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'There are four ways an individual can acquire Canadian citizenship: by birth on Canadian soil; by descent (being born to a Canadian parent); by grant (naturalization); and by adoption. Among them, only citizenship by birth is granted automatically with limited exceptions, while citizenship by descent or adoption is acquired automatically if the specified conditions have been met. Citizenship by grant, on the other hand, must be approved by the Minister of Immigration, Refugees and Citizenship.', shape=(), dtype=string) tf.Tensor(b'Canadian nationality law', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for text, label in train_ds.take(1):\n",
    "    print(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_map(text,label):\n",
    "    text = tokenizer.texts_to_sequences([text.numpy().decode('utf-8')])[0]\n",
    "    label = tokenizer.texts_to_sequences([label.numpy().decode('utf-8')])[0]\n",
    "    return tf.constant(text), tf.constant(label)\n",
    "\n",
    "train_ds = train_ds.map(lambda text, label : tf.py_function(tokenize_map, [text, label], [tf.int32, tf.int32]))\n",
    "valid_ds = valid_ds.map(lambda text, label : tf.py_function(tokenize_map, [text, label], [tf.int32, tf.int32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  82   17  114 2132   19  593   47 4386  540  439   10  683    9  540\n",
      " 3281   10 3977   93  329    6    5  540 1195   10 2795 4824    3   10\n",
      " 2402  437  159   53  439   10  683    7 1742 2133   12  615 1434   70\n",
      "  439   10 3977   13 2402    7 1435 2133   72    1 2273 1322   27   54\n",
      " 1436  439   10 2795    9    1   42  505  163   20 1929   10    1 1539\n",
      "    2 2371 5115    3  439], shape=(75,), dtype=int32) tf.Tensor([ 540 1460   90], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for text, label in train_ds.take(1):\n",
    "    print(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763 13\n",
      "<class 'list'>\n",
      "62.0 2.0\n",
      "98.0 3.0\n",
      "161.0 6.0\n"
     ]
    }
   ],
   "source": [
    "length = [len(text) for text,_ in train_ds]\n",
    "label_len = [len(label) for _, label in train_ds]\n",
    "print(max(length), max(label_len)) # max length\n",
    "print(type(length))\n",
    "print(np.percentile(length, 30), np.percentile(label_len, 30)) # length at 30th percentile\n",
    "print(np.percentile(length, 60), np.percentile(label_len, 60)) # length at 60th percentile\n",
    "print(np.percentile(length, 90), np.percentile(label_len, 90)) # length at 90th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(text,label):\n",
    "    text = pad_sequences([text.numpy()], maxlen=128, padding='post')[0]\n",
    "    # Make the label of the size 1, with only keeping the most used sequence from the list\n",
    "    label = [np.bincount(label.numpy()).argmax()]\n",
    "    return text, label\n",
    "\n",
    "def gen_func(text, label):\n",
    "    text,label = tf.py_function(pad_sequence, [text, label], [tf.int32, tf.int32])\n",
    "    text = tf.convert_to_tensor(text, dtype=tf.int32)\n",
    "    label = tf.convert_to_tensor(label, dtype=tf.int32)\n",
    "    text.set_shape(tf.TensorShape([128]))\n",
    "    label.set_shape(tf.TensorShape([1]))\n",
    "    return text, label\n",
    "\n",
    "train_ds = train_ds.map(gen_func)\n",
    "valid_ds = valid_ds.map(gen_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  82   17  114 2132   19  593   47 4386  540  439   10  683    9  540\n",
      " 3281   10 3977   93  329    6    5  540 1195   10 2795 4824    3   10\n",
      " 2402  437  159   53  439   10  683    7 1742 2133   12  615 1434   70\n",
      "  439   10 3977   13 2402    7 1435 2133   72    1 2273 1322   27   54\n",
      " 1436  439   10 2795    9    1   42  505  163   20 1929   10    1 1539\n",
      "    2 2371 5115    3  439    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(128,), dtype=int32) tf.Tensor([90], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for text, label in train_ds.take(1):\n",
    "    print(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = train_ds.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "valid_ds = valid_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128) (32, 1)\n"
     ]
    }
   ],
   "source": [
    "for text,label in train_ds.take(1):\n",
    "    print(text.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32),\n",
    "    LSTM(64),\n",
    "    Dense(len(tokenizer.word_index), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 195ms/step - accuracy: 0.1318 - loss: 8.6206 - val_accuracy: 0.1257 - val_loss: 6.8437\n",
      "Epoch 2/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 190ms/step - accuracy: 0.1376 - loss: 6.0204 - val_accuracy: 0.1257 - val_loss: 6.8230\n",
      "Epoch 3/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 197ms/step - accuracy: 0.1403 - loss: 5.9532 - val_accuracy: 0.1257 - val_loss: 6.8741\n",
      "Epoch 4/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 186ms/step - accuracy: 0.1372 - loss: 5.9496 - val_accuracy: 0.1257 - val_loss: 6.9350\n",
      "Epoch 5/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 195ms/step - accuracy: 0.1399 - loss: 5.9180 - val_accuracy: 0.1257 - val_loss: 6.9671\n",
      "Epoch 6/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 179ms/step - accuracy: 0.1382 - loss: 5.8742 - val_accuracy: 0.1257 - val_loss: 7.0422\n",
      "Epoch 7/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 186ms/step - accuracy: 0.1388 - loss: 5.7868 - val_accuracy: 0.1260 - val_loss: 6.8990\n",
      "Epoch 8/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 185ms/step - accuracy: 0.1380 - loss: 5.6330 - val_accuracy: 0.1318 - val_loss: 6.8610\n",
      "Epoch 9/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 175ms/step - accuracy: 0.1461 - loss: 5.4208 - val_accuracy: 0.1284 - val_loss: 7.0119\n",
      "Epoch 10/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 163ms/step - accuracy: 0.1428 - loss: 5.2682 - val_accuracy: 0.1229 - val_loss: 7.0477\n",
      "Epoch 11/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 160ms/step - accuracy: 0.1468 - loss: 5.1398 - val_accuracy: 0.1180 - val_loss: 7.2071\n",
      "Epoch 12/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 183ms/step - accuracy: 0.1567 - loss: 5.0005 - val_accuracy: 0.1162 - val_loss: 7.4932\n",
      "Epoch 13/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 192ms/step - accuracy: 0.1496 - loss: 5.3610 - val_accuracy: 0.1144 - val_loss: 7.3654\n",
      "Epoch 14/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 170ms/step - accuracy: 0.1571 - loss: 5.0864 - val_accuracy: 0.1107 - val_loss: 7.4115\n",
      "Epoch 15/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 175ms/step - accuracy: 0.1709 - loss: 4.8210 - val_accuracy: 0.1131 - val_loss: 7.6021\n",
      "Epoch 16/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 184ms/step - accuracy: 0.1873 - loss: 4.7029 - val_accuracy: 0.1226 - val_loss: 7.6128\n",
      "Epoch 17/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 172ms/step - accuracy: 0.2058 - loss: 4.6289 - val_accuracy: 0.1128 - val_loss: 7.6473\n",
      "Epoch 18/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 96ms/step - accuracy: 0.2140 - loss: 4.7020 - val_accuracy: 0.1312 - val_loss: 7.7746\n",
      "Epoch 19/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - accuracy: 0.2492 - loss: 4.4210 - val_accuracy: 0.1358 - val_loss: 7.8438\n",
      "Epoch 20/20\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 105ms/step - accuracy: 0.2499 - loss: 4.3522 - val_accuracy: 0.1437 - val_loss: 7.8609\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=valid_ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Predicted Title: the, Actual Title: disney\n",
      "Predicted Title: and, Actual Title: from\n",
      "Predicted Title: four, Actual Title: drop\n",
      "Predicted Title: of, Actual Title: the\n",
      "Predicted Title: film, Actual Title: of\n",
      "Predicted Title: and, Actual Title: 8\n",
      "Predicted Title: tract, Actual Title: strand\n",
      "Predicted Title: league, Actual Title: red\n",
      "Predicted Title: and, Actual Title: king\n",
      "Predicted Title: and, Actual Title: ball\n",
      "Predicted Title: states, Actual Title: season\n",
      "Predicted Title: tract, Actual Title: full\n",
      "Predicted Title: in, Actual Title: money\n",
      "Predicted Title: s, Actual Title: and\n",
      "Predicted Title: season, Actual Title: birth\n",
      "Predicted Title: system, Actual Title: league\n",
      "Predicted Title: states, Actual Title: 3\n",
      "Predicted Title: water, Actual Title: energy\n",
      "Predicted Title: red, Actual Title: randy\n",
      "Predicted Title: cougar, Actual Title: character\n",
      "Predicted Title: film, Actual Title: in\n",
      "Predicted Title: puerto, Actual Title: to\n",
      "Predicted Title: tract, Actual Title: in\n",
      "Predicted Title: of, Actual Title: of\n",
      "Predicted Title: of, Actual Title: of\n",
      "Predicted Title: season, Actual Title: standard\n",
      "Predicted Title: s, Actual Title: double\n",
      "Predicted Title: cup, Actual Title: series\n",
      "Predicted Title: on, Actual Title: and\n",
      "Predicted Title: states, Actual Title: city\n",
      "Predicted Title: series, Actual Title: of\n",
      "Predicted Title: game, Actual Title: stephen\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in valid_ds.take(1):\n",
    "    prediction = model.predict(text_batch)\n",
    "    # print(prediction, label_batch)\n",
    "    predicted_id = tf.argmax(prediction, axis=-1).numpy()\n",
    "    predicted_title = tokenizer.sequences_to_texts([predicted_id])\n",
    "    predicted_title = predicted_title[0].split()\n",
    "    label_batch_list = label_batch.numpy()\n",
    "    actual_title = tokenizer.sequences_to_texts(label_batch_list)\n",
    "    for i in range(len(predicted_title)):\n",
    "        print(f\"Predicted Title: {predicted_title[i]}, Actual Title: {actual_title[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
